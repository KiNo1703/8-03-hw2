# Домашнее задание к занятию «Репликация и масштабирование. Часть 2» - Новиков Кирилл

# Задание 1

## 1. Активный Master-сервер и пассивный репликационный Slave-сервер

У нас есть один основной сервер (Master), который обрабатывает все запросы на запись и чтение, и его точная копия (Slave), которая постоянно синхронизируется с Master, но обычно не обслуживает пользователей.

Основные преимущества:

Повышение надежности и отказоустойчивости. Это главный плюс. Если основной Master-сервер «падает» (аппаратный сбой, ошибка и т.д.), мы можем быстро переключиться на Slave-сервер. Он встанет на место мастера, и работа приложения почти не прервется. Вместо часов простоя получаем минуты.

Резервное копирование без простоев. Обычно создание полной резервной копии большой базы данных нагружает сервер и может ухудшить его производительность для пользователей. Мы можем делать бэкапы с Slave-сервера, абсолютно не мешая работе основного Master.

Тестирование и аналитика. Можно использовать Slave-сервер для запуска тяжелых аналитических запросов или тестирования новых версий приложения на реальных данных, не создавая нагрузки на продакшен-базу (Master).

## 2. Master-сервер и несколько Slave-серверов



Один Master, но уже не один, а несколько Slave-серверов. Master по-прежнему принимает всю запись, но нагрузку по чтению теперь можно распределить между всеми репликами.

Основные преимущества:

Масштабирование чтения. Это ключевое преимущество. В большинстве веб-приложений запросов на чтение (показать страницу, вывести товары, прочитать ленту) в разы больше, чем на запись (оформить заказ, оставить комментарий). Мы можем распределить всю эту нагрузку по чтению между несколькими Slave-серверами. Добавив еще один Slave, мы практически линейно увеличиваем мощность по обработке запросов на чтение.

Еще более высокая отказоустойчивость. Если один из нескольких Slave-серверов выходит из строя, остальные продолжают работать и принимать нагрузку. Пользователи могут даже не заметить проблему. Система становится более устойчивой.

Географическое распределение. Slave-серверы можно размещать в разных дата-центрах по всему миру. Например, европейские пользователи будут читать данные с Slave в Европе, а американские — с Slave в США. Это drastically снижает задержку (latency) для конечных пользователей.

Гибкость использования реплик: Можно «заточить» разные Slave-серверы под разные задачи:
Один — для основных запросов веб-сайта.
Второй — только для тяжелой бизнес-аналитики и отчетов.
Третий — для создания резервных копий.

# Задание 2

У нас есть одна база данных (БД) с тремя таблицами:
users (пользователи)
books (книги)
shops (магазины)

1. Вертикальный шардинг (Разделение по ответственности)
Принцип: Разделяем таблицы по их функциональному назначению и типу нагрузки на разные серверы баз данных.

План разграничения:
Сервер БД №1: User Profile DB (Пользовательские данные)

Размещается таблица: users
Причина: Данные пользователей (логины, пароли, личная информация) являются критически важными, требуют высокого уровня безопасности и часто участвуют в аутентификации. Их лучше изолировать.

Сервер БД №2: Product & Commerce DB (Данные каталога и коммерции)
Размещаются таблицы: books, shops
Причина: Эти таблицы тесно связаны бизнес-логикой (книги продаются в магазинах). Объединение их на одном сервере позволяет выполнять сложные JOIN-запросы (например, "найти все магазины, где есть определенная книга") без межсерверного взаимодействия, что сильно ускоряет работу.

Преимущества такого подхода:
Изоляция отказов: Если сервер с книгами перегружен, это не затронет процесс логина пользователей.
Оптимизация под нагрузку: Каждый сервер можно оптимизировать под свой тип данных (например, выделить больше памяти для кеша книг).
Безопасность: Доступ к пользовательским данным можно ограничить только одному серверу приложения.

2. Горизонтальный шардинг (Разделение по объему данных)
Принцип: Одну и ту же таблицу разбиваем на части (шарды) и распределяем по разным серверам на основе определенного ключа. 

План разграничения (предположим, что таблица books стала очень большой):
Ключ шардирования (Shard Key): shop_id (ID магазина).
Причина: Это естественный ключ. Все книги принадлежат определенному магазину, и большинство запросов будет в рамках одного магазина (например, "показать все книги в моем магазине").

Принцип разбивки:
Шард 1: books WHERE shop_id <= 1000
Шард 2: books WHERE shop_id > 1000 AND shop_id <= 2000
Шард N: ... и так далее.

Как находится нужный шард?
В приложении или через промежуточное ПО (middleware) создается "Конфигуратор шардов". Это может быть отдельная база или сервис, который хранит соответствие shop_id -> Shard Server.
Когда приложению нужно найти книгу по shop_id, оно сначала спрашивает у конфигуратора: "На каком сервере лежат данные для shop_id=1500?". Конфигуратор отвечает: "Обращайся на Product Shard 2".


<img width="2849" height="1907" alt="Схема" src="https://github.com/user-attachments/assets/a7e8e4e5-887d-45c7-b9c6-a8a066065e47" />

